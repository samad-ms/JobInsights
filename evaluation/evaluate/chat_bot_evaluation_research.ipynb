{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import TextLoader\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "\n",
    "# loader = TextLoader(\"description.txt\",encoding='latin1')\n",
    "# documents = loader.load_and_split(text_splitter)\n",
    "# len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# vectorstore = FAISS.from_documents(\n",
    "#     documents, embedding=OpenAIEmbeddings()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df = pd.DataFrame([d.page_content for d in documents], columns=[\"text\"])\n",
    "# df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from giskard.rag import KnowledgeBase\n",
    "\n",
    "# knowledge_base = KnowledgeBase(df)\n",
    "# knowledge_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from giskard.rag import generate_testset\n",
    "\n",
    "# testset = generate_testset(\n",
    "#     knowledge_base,\n",
    "#     num_questions=50,\n",
    "#     agent_description=\"A chatbot answering questions about job summarization and job requirements by considering real time job descriptions as context\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set_df = testset.to_pandas()\n",
    "\n",
    "# for index, row in enumerate(test_set_df.head(3).iterrows()):\n",
    "#     print(f\"Question {index + 1}: {row[1]['question']}\")\n",
    "#     print(f\"Reference answer: {row[1]['reference_answer']}\")\n",
    "#     print(\"Reference context:\")\n",
    "#     print(row[1]['reference_context'])\n",
    "#     print(\"******************\", end=\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testset.save(\"test-set.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.prompts import PromptTemplate\n",
    "\n",
    "# template = \"\"\"\n",
    "# Answer the question based on the context below. If you can't \n",
    "# answer the question, reply \"I don't know\".\n",
    "\n",
    "# Context: {context}\n",
    "\n",
    "# Question: {question}\n",
    "# \"\"\"\n",
    "\n",
    "# prompt = PromptTemplate.from_template(template)\n",
    "# print(prompt.format(context=\"Here is some context\", question=\"Here is a question\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever.invoke(\"what are the skills needed for data science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     MessagesPlaceholder(variable_name='chat_history'),\n",
    "#     ('user', \"{input}\"),\n",
    "#     ('user', \"Given the above conversation, generate a search query to look up in order to get the relevant information based on the conversation\")\n",
    "# ])\n",
    "# llm = ChatOpenAI()\n",
    "# history_aware_retriever_chain = create_history_aware_retriever(\n",
    "#     llm, retriever, prompt\n",
    "# )\n",
    "\n",
    "\n",
    "# def get_rag_chain(history_aware_retriever_chain):\n",
    "#     # Define the prompt template for the RAG chain\n",
    "#     prompt = ChatPromptTemplate.from_messages([\n",
    "#         (\"system\", \"Answer the user's questions based on below context:\\n\\n{context}\"),\n",
    "#         MessagesPlaceholder(variable_name='chat_history'),\n",
    "#         ('user', \"{input}\"),\n",
    "#     ])\n",
    "#     llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "#     stuff_documents_chain = create_stuff_documents_chain(llm, prompt)\n",
    "#     rag_chain = create_retrieval_chain(history_aware_retriever_chain, stuff_documents_chain)\n",
    "#     return rag_chain\n",
    "\n",
    "# def get_response(user_query,history=\" \"):\n",
    "#     context_retriever_chain = get_context_retriever(vectore_store=db)\n",
    "#     rag_chain = get_rag_chain(context_retriever_chain)\n",
    "    \n",
    "#     response = rag_chain.invoke({\n",
    "#         \"chat_history\": history,\n",
    "#         \"input\": user_query\n",
    "#     })\n",
    "#     return response['answer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"what are the skills needed for data science?\"\n",
    "\n",
    "# result = get_response(question)\n",
    "\n",
    "# print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from giskard.rag import evaluate\n",
    "\n",
    "# report = evaluate(get_response, testset=testset, knowledge_base=knowledge_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report.correctness_by_question_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report.get_failures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "job-insights",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
